{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0afe0ca7-2df2-47ee-bcac-61e4f89bc67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS]\n"
     ]
    }
   ],
   "source": [
    "# IMPORT LIBRARIES\n",
    "try:\n",
    "    # PYSPARK\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark import SparkContext\n",
    "    from pyspark.sql import SQLContext\n",
    "    from pyspark.sql import DataFrame\n",
    "    import pyspark.sql.types as tp\n",
    "    import pyspark.sql.functions as F\n",
    "    \n",
    "    #Py Spark ML Libraries\n",
    "    from pyspark.ml.classification import LogisticRegression\n",
    "    from pyspark.ml.regression import LinearRegression\n",
    "    from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, StandardScaler\n",
    "    from pyspark.ml import Pipeline\n",
    "    from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "    \n",
    "    # OTHER LIBRARIES\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import glob\n",
    "    from functools import reduce\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from urllib.request import urlopen\n",
    "    import datetime\n",
    "    from pathlib import Path\n",
    "    \n",
    "    print('[SUCCESS]')\n",
    "\n",
    "    #CATCH ERROR IMPORTING A LIBRARY\n",
    "except ImportError as ie:\n",
    "    raise ImportError(f'[Error importing]: {ie}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2401bf77-ef66-4e5f-83f2-22e50cc80380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESSFULLY RUNNING SPARK SESSION]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "INITIALIZING SPARK SESSION\n",
    "- NAME IS SET FOR SPARK SESSION WHEN RUNNING ON LOCAL HOST\n",
    "'''\n",
    "spark = SparkSession.builder.master('local').config(\"spark.executor.memory\", \"1g\").config(\"spark.driver.memory\", \"2g\").appName('UsedCar_Project').getOrCreate()\n",
    "print('[SUCCESSFULLY RUNNING SPARK SESSION]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f75fc5c-bfbe-4bbf-bb1e-7fa12c97e8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-14 02:38:24--  https://storage.googleapis.com/iamangelsh-public-datasets/car_prices.csv\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.190.80, 142.250.191.112, 142.250.190.112, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.190.80|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 89088424 (85M) [application/vnd.ms-excel]\n",
      "Saving to: ‘car_prices.csv’\n",
      "\n",
      "car_prices.csv      100%[===================>]  84.96M  6.53MB/s    in 13s     \n",
      "\n",
      "2022-04-14 02:38:38 (6.36 MB/s) - ‘car_prices.csv’ saved [89088424/89088424]\n",
      "\n",
      "+----+-----+-------------------+----------+-----+------------+-----------------+-----+---------+--------+-----+--------+--------------------+-----+------------+-----------+-------------+--------------+\n",
      "|year| make|              model|      trim| body|transmission|              vin|state|condition|odometer|color|interior|              seller|  mmr|sellingprice|   saledate|saledate_year|saledate_month|\n",
      "+----+-----+-------------------+----------+-----+------------+-----------------+-----+---------+--------+-----+--------+--------------------+-----+------------+-----------+-------------+--------------+\n",
      "|2015|  Kia|            Sorento|        LX|  SUV|   automatic|5xyktca69fg566472|   ca|      5.0| 16639.0|white|   black|kia motors americ...|20500|       21500|Dec 16 2014|         2014|           Dec|\n",
      "|2015|  Kia|            Sorento|        LX|  SUV|   automatic|5xyktca69fg561319|   ca|      5.0|  9393.0|white|   beige|kia motors americ...|20800|       21500|Dec 16 2014|         2014|           Dec|\n",
      "|2014|  BMW|           3 Series|328i SULEV|Sedan|   automatic|wba3c1c51ek116351|   ca|      4.5|  1331.0| gray|   black|financial service...|31900|       30000|Jan 15 2015|         2015|           Jan|\n",
      "|2015|Volvo|                S60|        T5|Sedan|   automatic|yv1612tb4f1310987|   ca|      4.1| 14282.0|white|   black|volvo na rep/worl...|27500|       27750|Jan 29 2015|         2015|           Jan|\n",
      "|2014|  BMW|6 Series Gran Coupe|      650i|Sedan|   automatic|wba6b2c57ed129731|   ca|      4.3|  2641.0| gray|   black|financial service...|66000|       67000|Dec 18 2014|         2014|           Dec|\n",
      "+----+-----+-------------------+----------+-----+------------+-----------------+-----+---------+--------+-----+--------+--------------------+-----+------------+-----------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Number of columns: 18 \n",
      "Number of Rows: 472336\n",
      "\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- make: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- trim: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- transmission: string (nullable = true)\n",
      " |-- vin: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- condition: double (nullable = true)\n",
      " |-- odometer: double (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- interior: string (nullable = true)\n",
      " |-- seller: string (nullable = true)\n",
      " |-- mmr: integer (nullable = true)\n",
      " |-- sellingprice: integer (nullable = true)\n",
      " |-- saledate: string (nullable = true)\n",
      " |-- saledate_year: integer (nullable = true)\n",
      " |-- saledate_month: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    '''\n",
    "    car_prices.csv is uploaded to a google bucket for public use. Since file is too large to push to GitHub for others to use from repo\n",
    "    this function will load the data from the google bucket.\n",
    "    \n",
    "    You can run this function each time and it will not download a new dataset each time since the first time you run it, it will download locally to your directory.\n",
    "    --- unless you delete it each time\n",
    "    \n",
    "    Function will check to make sure file is in the directory\n",
    "    - if it is, load it to a spark dataframe\n",
    "    - if it is not, download it, then load it to a spark dataframe\n",
    "    \n",
    "    SCHEMA:\n",
    "    - Created a schema to make sure the data types for the file being read is kept\n",
    "    \n",
    "    \n",
    "    Drop Randome Values in state columns\n",
    "    \n",
    "    \n",
    "    WARNING: TO USE THIS FUNCTION, YOU HAVE TO BE RUNNING JUPYTER NOTEBOOK ON A LINUX SERVER (USE DOCKER)\n",
    "    \n",
    "    NOTES:\n",
    "    option(\"header\",True).option(\"inferSchema\", True)\n",
    "    '''\n",
    "    \n",
    "    # CHECKS TO SEE IF FILE EXIST\n",
    "    path = Path('car_prices.csv') \n",
    "    \n",
    "    # IF FILE DOES NOT EXIST\n",
    "    if not path.is_file():\n",
    "        !wget https://storage.googleapis.com/iamangelsh-public-datasets/car_prices.csv \n",
    "    \n",
    "    \n",
    "    \n",
    "    # CREATE SCHEMA TO KEEP DATA TYPES\n",
    "    schema = tp.StructType([tp.StructField('year', tp.IntegerType(), True),\n",
    "                           tp.StructField('make', tp.StringType(), True),\n",
    "                           tp.StructField('model', tp.StringType(), True),\n",
    "                           tp.StructField('trim', tp.StringType(), True),\n",
    "                           tp.StructField('body', tp.StringType(), True),\n",
    "                           tp.StructField('transmission', tp.StringType(), True),\n",
    "                           tp.StructField('vin', tp.StringType(), True),\n",
    "                           tp.StructField('state', tp.StringType(), True),\n",
    "                           tp.StructField('condition', tp.DoubleType(), True),\n",
    "                           tp.StructField('odometer', tp.DoubleType(), True),\n",
    "                           tp.StructField('color', tp.StringType(), True),\n",
    "                           tp.StructField('interior', tp.StringType(), True),\n",
    "                           tp.StructField('seller', tp.StringType(), True),\n",
    "                           tp.StructField('mmr', tp.IntegerType(), True),\n",
    "                           tp.StructField('sellingprice', tp.IntegerType(), True),\n",
    "                           tp.StructField('saledate', tp.StringType(), True)])\n",
    "    \n",
    "    \n",
    "    # LOAD IN DATA WITH SCHEMA\n",
    "    df = spark.read.csv(\"car_prices.csv\", header = True, sep=\",\", schema=schema)\n",
    "    \n",
    "    # FILTER OUT VIN NUMBERS FROM STATE COLUMN\n",
    "    df = df.where(F.length(F.col(\"state\")) <= 2)\n",
    "    \n",
    "    # DROP ROWS THAT CONTAIN NULL VALUES\n",
    "    df = df.na.drop('any')\n",
    "    \n",
    "    # CREATE THRESHOLD FOR CONDITION COLUMN\n",
    "    new_df = df.withColumn(\n",
    "        'condition', \n",
    "        F.when(df.condition > 3.75, 'Great'\n",
    "        ).when((df.condition >= 2) & (df.condition <= 3.75), 'Average'\n",
    "        ).when(df.condition < 2, 'Bad'))\n",
    "    \n",
    "    # DROP COLUMNS THAT WON'T BE USED\n",
    "    cols = ('trim', 'vin', 'interior', 'seller')\n",
    "    new_df = new_df.drop(*cols)\n",
    "    \n",
    "    \n",
    "    # USE MM DD YYYY FOR SALEDATE COLUMN\n",
    "    new_df = df.withColumn(\n",
    "        'saledate', F.substring('saledate', 5,11)\n",
    "        ).withColumn(\n",
    "        'saledate_year', F.substring('saledate', 7,5)\n",
    "        ).withColumn(\n",
    "        'saledate_month', F.substring('saledate', 1,3))\n",
    "    new_df = new_df.withColumn(\n",
    "        'saledate_year', F.col('saledate_year').cast(tp.IntegerType())\n",
    "        )\n",
    "    \n",
    "    # RETURN NEW DATAFRAME\n",
    "    return new_df\n",
    "\n",
    "\n",
    "# LOAD THE DATA\n",
    "df = load_data()\n",
    "\n",
    "# SHOW DATA\n",
    "df.show(5)\n",
    "\n",
    "# SHOW NUMBER OF COLUMNS AND ROWS\n",
    "print(f'Number of columns: {len(df.columns)} \\nNumber of Rows: {df.count()}')\n",
    "print()\n",
    "\n",
    "# SHOW SCHEMA - DATATYPES\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c21b621a-c694-4307-b524-81839badbcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "\n",
    "# Try to predict selling price using gradient trees regressor\n",
    "import pyspark.ml.feature as ft\n",
    "\n",
    "features = ['year','condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fff67a81-1a33-434a-9dcc-70b87ec81ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate the features together and use the ChiSqSelector to select only the top 2 most important features\n",
    "featuresCreator = ft.VectorAssembler(inputCols=[col for col in features[1:]], outputCol='features')\n",
    "selector = ft.ChiSqSelector(numTopFeatures=2, outputCol=\"selectedFeatures\", labelCol='sellingprice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7651c761-9fae-43b5-98a8-ab093146a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to predict the selling price, we will use the gradient boosted trees generator\n",
    "import pyspark.ml.regression as reg\n",
    "regressor = reg.GBTRegressor(maxIter=15, maxDepth=3, labelCol='sellingprice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fb64499-a897-442e-be6b-9a381307f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in train and test \n",
    "df_train, df_test = df.randomSplit([0.7,0.3], seed=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7592bfae-1ee6-4e33-a6a7-dc76b974d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We put it all together into a Pipeline\n",
    "pipeline = Pipeline(stages=[featuresCreator, selector, regressor])\n",
    "selling_price = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c287ff79-5217-47c2-901e-e52321d4b139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2919344116563881\n",
      "8092.992894809114\n"
     ]
    }
   ],
   "source": [
    "# Check if mour model performs well on testing data\n",
    "import pyspark.ml.evaluation as ev\n",
    "\n",
    "evaluator = ev.RegressionEvaluator(predictionCol=\"prediction\", labelCol='sellingprice')\n",
    "\n",
    "print(evaluator.evaluate(selling_price.transform(df_test), {evaluator.metricName: 'r2'}))\n",
    "print(evaluator.evaluate(selling_price.transform(df_test), {evaluator.metricName: 'rmse'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b45ac-887e-47a6-8e39-4d3ccf85d895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1bf555-ada5-41f7-8b25-b23052cccc09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c990b3a9-4755-4e3e-87ba-463abec94db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
