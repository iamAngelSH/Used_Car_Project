{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38659056-5832-4756-b228-47d2db8664f5",
   "metadata": {},
   "source": [
    "# Used Car Auction Sales Data Analysis and Machine Learning\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d82c6c5-7db3-4913-a789-d760bb475d0f",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25e77629-2f3b-4b1f-b7e8-2682eacee61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS]\n"
     ]
    }
   ],
   "source": [
    "# IMPORT LIBRARIES\n",
    "try:\n",
    "    # PYSPARK\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark import SparkContext\n",
    "    from pyspark.sql import SQLContext\n",
    "    from pyspark.sql import DataFrame\n",
    "    import pyspark.sql.types as tp\n",
    "    import pyspark.sql.functions as F\n",
    "    from pyspark.sql.functions import udf\n",
    "    from pyspark.sql.types import DoubleType\n",
    "    \n",
    "    #Py Spark ML Libraries\n",
    "    from pyspark.ml.regression import GBTRegressor\n",
    "    from pyspark.ml.regression import LinearRegression\n",
    "    from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, StandardScaler\n",
    "    from pyspark.ml import Pipeline\n",
    "    from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "    from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    from pyspark.mllib.stat import Statistics\n",
    "    from pyspark.ml.feature import MinMaxScaler\n",
    "    \n",
    "    # OTHER LIBRARIES\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import glob\n",
    "    from functools import reduce\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from urllib.request import urlopen\n",
    "    import datetime\n",
    "    from pathlib import Path\n",
    "    import six\n",
    "    from datetime import datetime\n",
    "    \n",
    "    print('[SUCCESS]')\n",
    "\n",
    "    #CATCH ERROR IMPORTING A LIBRARY\n",
    "except ImportError as ie:\n",
    "    raise ImportError(f'[Error importing]: {ie}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea5a740-50e4-4757-a8c9-484e07fe6c60",
   "metadata": {},
   "source": [
    "## Initializing Spark session and cluster for work enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08719bc8-8e9f-4281-9925-36130833754c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESSFULLY RUNNING SPARK SESSION] -- 2022-04-23 02:48:15.827201\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "INITIALIZING SPARK SESSION\n",
    "- NAME IS SET FOR SPARK SESSION WHEN RUNNING ON LOCAL HOST\n",
    "'''\n",
    "# IF RUNNING ON DOCKER (LOCAL) \n",
    "spark = SparkSession.builder.master('local').config(\"spark.executor.memory\", \"1g\").config(\"spark.driver.memory\", \"2g\").appName('UsedCar_Project').getOrCreate()\n",
    "\n",
    "# IF RUNNING ON AMAZON BUCKER (UNCOMMENT AND COMMENT THE TOP\n",
    "# spark = SparkSession.builder.master('spark://spark-master:7077').config(\"spark.executor.memory\", \"1g\").config(\"spark.driver.memory\", \"2g\").appName('UsedCar_Project').getOrCreate()\n",
    "print(f'[SUCCESSFULLY RUNNING SPARK SESSION] -- {datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abbde70-1485-4e89-90fe-405ffd78841c",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea3ca12c-84e6-4f9d-a7b9-cbb4d7035cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------------------+-----+------------+-----+---------+--------+-----+-----+------------+-----------+-------------+--------------+\n",
      "|year| make|              model| body|transmission|state|condition|odometer|color|  mmr|sellingprice|   saledate|saledate_year|saledate_month|\n",
      "+----+-----+-------------------+-----+------------+-----+---------+--------+-----+-----+------------+-----------+-------------+--------------+\n",
      "|2015|  Kia|            Sorento|  SUV|   automatic|   ca|    Great| 16639.0|white|20500|       21500|Dec 16 2014|         2014|           Dec|\n",
      "|2015|  Kia|            Sorento|  SUV|   automatic|   ca|    Great|  9393.0|white|20800|       21500|Dec 16 2014|         2014|           Dec|\n",
      "|2014|  BMW|           3 Series|Sedan|   automatic|   ca|    Great|  1331.0| gray|31900|       30000|Jan 15 2015|         2015|           Jan|\n",
      "|2015|Volvo|                S60|Sedan|   automatic|   ca|    Great| 14282.0|white|27500|       27750|Jan 29 2015|         2015|           Jan|\n",
      "|2014|  BMW|6 Series Gran Coupe|Sedan|   automatic|   ca|    Great|  2641.0| gray|66000|       67000|Dec 18 2014|         2014|           Dec|\n",
      "+----+-----+-------------------+-----+------------+-----+---------+--------+-----+-----+------------+-----------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Data for uncleaned DataFrame\n",
      "Number of columns: 16 \n",
      "Number of Rows: 558837\n",
      "\n",
      "Data for cleaned DataFrame\n",
      "Number of columns: 14 \n",
      "Number of Rows: 472336\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- make: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- transmission: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- odometer: double (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- mmr: integer (nullable = true)\n",
      " |-- sellingprice: integer (nullable = true)\n",
      " |-- saledate: string (nullable = true)\n",
      " |-- saledate_year: integer (nullable = true)\n",
      " |-- saledate_month: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    '''\n",
    "    car_prices.csv is uploaded to a google bucket for public use. Since file is too large to push to GitHub for others to use from repo\n",
    "    this function will load the data from the google bucket.\n",
    "    \n",
    "    You can run this function each time and it will not download a new dataset each time since the first time you run it, it will download locally to your directory.\n",
    "    --- unless you delete it each time\n",
    "    \n",
    "    Function will check to make sure file is in the directory\n",
    "    - if it is, load it to a spark dataframe\n",
    "    - if it is not, download it, then load it to a spark dataframe\n",
    "    \n",
    "    SCHEMA:\n",
    "    - Created a schema to make sure the data types for the file being read is kept\n",
    "    \n",
    "    \n",
    "    Drop Randome Values in state columns\n",
    "    \n",
    "    \n",
    "    WARNING: TO USE THIS FUNCTION, YOU HAVE TO BE RUNNING JUPYTER NOTEBOOK ON A LINUX SERVER (USE DOCKER)\n",
    "    \n",
    "    NOTES:\n",
    "    option(\"header\",True).option(\"inferSchema\", True)\n",
    "    '''\n",
    "    \n",
    "    # CHECKS TO SEE IF FILE EXIST\n",
    "    path = Path('car_prices.csv') \n",
    "    \n",
    "    # IF FILE DOES NOT EXIST\n",
    "    if not path.is_file():\n",
    "        !wget https://storage.googleapis.com/iamangelsh-public-datasets/car_prices.csv \n",
    "    \n",
    "    \n",
    "    \n",
    "    # CREATE SCHEMA TO KEEP DATA TYPES\n",
    "    schema = tp.StructType([tp.StructField('year', tp.IntegerType(), True),\n",
    "                           tp.StructField('make', tp.StringType(), True),\n",
    "                           tp.StructField('model', tp.StringType(), True),\n",
    "                           tp.StructField('trim', tp.StringType(), True),\n",
    "                           tp.StructField('body', tp.StringType(), True),\n",
    "                           tp.StructField('transmission', tp.StringType(), True),\n",
    "                           tp.StructField('vin', tp.StringType(), True),\n",
    "                           tp.StructField('state', tp.StringType(), True),\n",
    "                           tp.StructField('condition', tp.DoubleType(), True),\n",
    "                           tp.StructField('odometer', tp.DoubleType(), True),\n",
    "                           tp.StructField('color', tp.StringType(), True),\n",
    "                           tp.StructField('interior', tp.StringType(), True),\n",
    "                           tp.StructField('seller', tp.StringType(), True),\n",
    "                           tp.StructField('mmr', tp.IntegerType(), True),\n",
    "                           tp.StructField('sellingprice', tp.IntegerType(), True),\n",
    "                           tp.StructField('saledate', tp.StringType(), True)])\n",
    "    \n",
    "    \n",
    "    # LOAD IN DATA WITH SCHEMA\n",
    "    df = spark.read.csv(\"car_prices.csv\", header = True, sep=\",\", schema=schema)\n",
    "    \n",
    "    old_df = df\n",
    "    \n",
    "    \n",
    "    # FILTER OUT VIN NUMBERS FROM STATE COLUMN\n",
    "    df = df.where(F.length(F.col(\"state\")) <= 2)\n",
    "    \n",
    "    # DROP ROWS THAT CONTAIN NULL VALUES\n",
    "    df = df.na.drop('any')\n",
    "    \n",
    "    # CREATE THRESHOLD FOR CONDITION COLUMN\n",
    "    df = df.withColumn(\n",
    "        'condition', \n",
    "        F.when(df.condition > 3.75, 'Great'\n",
    "        ).when((df.condition >= 2) & (df.condition <= 3.75), 'Average'\n",
    "        ).when(df.condition < 2, 'Bad'))\n",
    "    \n",
    "    # DROP COLUMNS THAT WON'T BE USED\n",
    "    cols = ('trim', 'vin', 'interior', 'seller')\n",
    "    df = df.drop(*cols)\n",
    "    \n",
    "    # USE MM DD YYYY FOR SALEDATE COLUMN\n",
    "    df = df.withColumn(\n",
    "        'saledate', F.substring('saledate', 5,11)\n",
    "        ).withColumn(\n",
    "        'saledate_year', F.substring('saledate', 7,5)\n",
    "        ).withColumn(\n",
    "        'saledate_month', F.substring('saledate', 1,3))\n",
    "    \n",
    "    df = df.withColumn(\n",
    "        'saledate_year', F.col('saledate_year').cast(tp.IntegerType())\n",
    "        )\n",
    "    \n",
    "    # RETURN NEW DATAFRAME\n",
    "    return df, old_df\n",
    "\n",
    "\n",
    "# LOAD THE DATA\n",
    "df, old_df = load_data()\n",
    "\n",
    "# SHOW DATA\n",
    "df.show(5)\n",
    "\n",
    "# SHOW NUMBER OF COLUMNS AND ROWS\n",
    "print('Data for uncleaned DataFrame')\n",
    "print(f'Number of columns: {len(old_df.columns)} \\nNumber of Rows: {old_df.count()}')\n",
    "print()\n",
    "print('Data for cleaned DataFrame')\n",
    "print(f'Number of columns: {len(df.columns)} \\nNumber of Rows: {df.count()}')\n",
    "\n",
    "\n",
    "# SHOW SCHEMA - DATATYPES\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb3cc5-4032-46db-b609-55f89dd6ad41",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preliminary Data Analysis\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98834cec-aff1-474a-a9ce-0f21512cbdbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "102228fa-4731-4d75-8f14-0fd80b11196d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+-----+-----+------------+---+-----+---------+--------+-----+--------+------+---+------------+--------+\n",
      "|year| make|model| trim| body|transmission|vin|state|condition|odometer|color|interior|seller|mmr|sellingprice|saledate|\n",
      "+----+-----+-----+-----+-----+------------+---+-----+---------+--------+-----+--------+------+---+------------+--------+\n",
      "|   0|10301|10399|10651|13195|       65353|  4|    0|    11820|      94|  749|     749|     0| 26|           0|       0|\n",
      "+----+-----+-----+-----+-----+------------+---+-----+---------+--------+-----+--------+------+---+------------+--------+\n",
      "\n",
      "After dropping Null values\n",
      "\n",
      "+----+----+-----+----+------------+-----+---------+--------+-----+---+------------+--------+-------------+--------------+\n",
      "|year|make|model|body|transmission|state|condition|odometer|color|mmr|sellingprice|saledate|saledate_year|saledate_month|\n",
      "+----+----+-----+----+------------+-----+---------+--------+-----+---+------------+--------+-------------+--------------+\n",
      "|   0|   0|    0|   0|           0|    0|        0|       0|    0|  0|           0|       0|            0|             0|\n",
      "+----+----+-----+----+------------+-----+---------+--------+-----+---+------------+--------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def null_values(df):\n",
    "    '''\n",
    "    TAKES IN A DATAFRAME AND RETURNS THE COUNT OF NULL VALUES IN EACH COLUMN\n",
    "    '''\n",
    "    return df.agg(*[F.count(F.when(F.isnull(c), c)).alias(c) for c in df.columns])\n",
    "\n",
    "NULL_VAL_COUNTS_OLD_DF = null_values(old_df)\n",
    "NULL_VAL_COUNTS_OLD_DF.show()\n",
    "\n",
    "print('After dropping Null values')\n",
    "print()\n",
    "NULL_VAL_COUNTS = null_values(df)\n",
    "NULL_VAL_COUNTS.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf3b24-3bc4-481c-8009-6315daf13062",
   "metadata": {},
   "source": [
    "## Look for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aca5d3a-97bf-4fc4-9cd1-52380446c52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+------------+------------+------------+-----+---------+--------+-----+-----+------------+-----------+-------------+--------------+\n",
      "|year|         make|       model|        body|transmission|state|condition|odometer|color|  mmr|sellingprice|   saledate|saledate_year|saledate_month|\n",
      "+----+-------------+------------+------------+------------+-----+---------+--------+-----+-----+------------+-----------+-------------+--------------+\n",
      "|2003|Mercedes-Benz|     E-Class|       Sedan|   automatic|   ga|  Average|     1.0|black| 7325|           1|Jan 06 2015|         2015|           Jan|\n",
      "|2014|         Ford|E-Series Van|E-Series Van|   automatic|   tx|    Great| 31886.0|white|20800|           1|Feb 12 2015|         2015|           Feb|\n",
      "+----+-------------+------------+------------+------------+-----+---------+--------+-----+-----+------------+-----------+-------------+--------------+\n",
      "\n",
      "+----+---------+--------------+-------------+------------+-----+---------+--------+------+-----+------------+-----------+-------------+--------------+\n",
      "|year|     make|         model|         body|transmission|state|condition|odometer| color|  mmr|sellingprice|   saledate|saledate_year|saledate_month|\n",
      "+----+---------+--------------+-------------+------------+-----+---------+--------+------+-----+------------+-----------+-------------+--------------+\n",
      "|2013|  Hyundai| Elantra Coupe|Elantra Coupe|   automatic|   ca|      Bad|999999.0|  blue| 8025|        2500|Jan 27 2015|         2015|           Jan|\n",
      "|2003|Chevrolet|Silverado 1500| Extended Cab|   automatic|   ca|  Average|999999.0|  gray| 1425|         700|Dec 16 2014|         2014|           Dec|\n",
      "|2009|    Dodge|       Charger|        Sedan|   automatic|   il|      Bad|999999.0| black| 3850|        1700|Dec 23 2014|         2014|           Dec|\n",
      "|2009|    Dodge|       Charger|        Sedan|   automatic|   tx|      Bad|999999.0|  blue| 4150|        5500|Jan 08 2015|         2015|           Jan|\n",
      "|2006|      Kia|        Amanti|        Sedan|   automatic|   ms|      Bad|999999.0|  gray|  900|         800|Dec 18 2014|         2014|           Dec|\n",
      "|2012|   Nissan|        Altima|        Sedan|   automatic|   oh|      Bad|999999.0| white| 7375|         800|Jan 06 2015|         2015|           Jan|\n",
      "|2009|    Dodge| Grand Caravan|      Minivan|   automatic|   md|      Bad|999999.0| black| 3325|        1500|Dec 23 2014|         2014|           Dec|\n",
      "|2006|     Ford|         F-150|    SuperCrew|   automatic|   ga|      Bad|999999.0| black| 7500|        3600|Feb 17 2015|         2015|           Feb|\n",
      "|2005|   Nissan|         Quest|      Minivan|   automatic|   il|      Bad|999999.0| green| 2250|        2600|Dec 30 2014|         2014|           Dec|\n",
      "|2013|      Kia|        Optima|        Sedan|   automatic|   ca|      Bad|999999.0| black|17700|        2700|Jan 13 2015|         2015|           Jan|\n",
      "|2010|Chevrolet|        Cobalt|        Sedan|   automatic|   ny|      Bad|999999.0|silver| 2850|         275|Dec 31 2014|         2014|           Dec|\n",
      "|2008|Chevrolet|        Impala|        Sedan|   automatic|   md|      Bad|999999.0|  gray| 1850|        1100|Feb 17 2015|         2015|           Feb|\n",
      "|2012|  Hyundai|        Sonata|        Sedan|   automatic|   oh|      Bad|999999.0| white| 9275|         800|Jan 06 2015|         2015|           Jan|\n",
      "|2005|     Ford|        Escape|          SUV|   automatic|   ms|      Bad|999999.0|  gray|  850|        1300|Jan 08 2015|         2015|           Jan|\n",
      "|2004|Chevrolet|         Tahoe|          SUV|   automatic|   ga|      Bad|999999.0| black|  875|        1800|Jan 06 2015|         2015|           Jan|\n",
      "|2013|     Ford|        Escape|          SUV|   automatic|   fl|      Bad|999999.0|  gray|10750|        3000|Jan 12 2015|         2015|           Jan|\n",
      "|2005|   Nissan|         Quest|      Minivan|   automatic|   md|  Average|999999.0| white| 1725|        1100|Jan 13 2015|         2015|           Jan|\n",
      "|2005|    Volvo|           S40|        Sedan|   automatic|   il|      Bad|999999.0|  gray| 1200|         550|Jan 13 2015|         2015|           Jan|\n",
      "|2014|    Dodge|       Journey|          SUV|   automatic|   tx|      Bad|999999.0| black|12800|        6000|Jan 21 2015|         2015|           Jan|\n",
      "|2010|    Mazda|          CX-7|          SUV|   automatic|   tx|      Bad|999999.0|   red| 5600|        3200|Jan 15 2015|         2015|           Jan|\n",
      "+----+---------+--------------+-------------+------------+-----+---------+--------+------+-----+------------+-----------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+\n",
      "|records|\n",
      "+-------+\n",
      "|     60|\n",
      "+-------+\n",
      "\n",
      "+----+----------+---------------+------------+------------+-----+---------+--------+------+---+------------+-----------+-------------+--------------+\n",
      "|year|      make|          model|        body|transmission|state|condition|odometer| color|mmr|sellingprice|   saledate|saledate_year|saledate_month|\n",
      "+----+----------+---------------+------------+------------+-----+---------+--------+------+---+------------+-----------+-------------+--------------+\n",
      "|1997|     Honda|         Accord|       Sedan|      manual|   fl|      Bad|353083.0| black| 25|         500|Dec 18 2014|         2014|           Dec|\n",
      "|1997|      Ford|         Taurus|       Sedan|   automatic|   fl|  Average|286868.0|  gray| 25|         400|Jan 07 2015|         2015|           Jan|\n",
      "|2002| Chevrolet|         Malibu|       Sedan|   automatic|   fl|      Bad|284296.0|   red| 25|         300|Jan 14 2015|         2015|           Jan|\n",
      "|2001|       Kia|         Optima|       Sedan|   automatic|   ga|  Average|255003.0|  gray| 25|         700|Dec 30 2014|         2014|           Dec|\n",
      "|2001|  Chrysler|        Sebring| Convertible|   automatic|   ca|      Bad|223707.0|  blue| 25|         300|Dec 30 2014|         2014|           Dec|\n",
      "|2003|   Lincoln|       Town Car|       Sedan|   automatic|   fl|  Average|266564.0|   red| 25|        1800|Feb 03 2015|         2015|           Feb|\n",
      "|2003| Chevrolet|        Venture|     Minivan|   automatic|   ga|      Bad|252396.0| white| 25|         600|Feb 17 2015|         2015|           Feb|\n",
      "|2002|      Saab|            9-5|       Sedan|   automatic|   fl|  Average|171964.0|silver| 25|         800|May 21 2015|         2015|           May|\n",
      "|2000|    Nissan|         Maxima|       Sedan|   automatic|   fl|      Bad|229381.0| black| 25|         300|May 21 2015|         2015|           May|\n",
      "|2001| Chevrolet|           S-10|extended cab|   automatic|   nm|      Bad|263535.0| white| 25|         900|Jun 10 2015|         2015|           Jun|\n",
      "|1996|Oldsmobile|Cutlass Supreme|       sedan|   automatic|   oh|      Bad|267734.0| white| 25|         325|Jun 16 2015|         2015|           Jun|\n",
      "|2000|  Chrysler|            LHS|       Sedan|   automatic|   nc|      Bad|223937.0|  blue| 25|         650|Jan 14 2015|         2015|           Jan|\n",
      "|1999|     Dodge|        Durango|         SUV|   automatic|   la|      Bad|301645.0|  blue| 25|         300|Jan 21 2015|         2015|           Jan|\n",
      "|2003|     Buick|          Regal|       Sedan|   automatic|   va|  Average|258557.0| black| 25|         400|Dec 18 2014|         2014|           Dec|\n",
      "|1997|    Nissan|         Maxima|       Sedan|   automatic|   fl|      Bad|220607.0| black| 25|         300|Jan 27 2015|         2015|           Jan|\n",
      "|2003|    Saturn|            VUE|         SUV|   automatic|   ga|  Average|694978.0|silver| 25|         500|Jan 08 2015|         2015|           Jan|\n",
      "|2004| Chevrolet|       Cavalier|       Coupe|   automatic|   nc|      Bad|227889.0|orange| 50|         550|Jan 28 2015|         2015|           Jan|\n",
      "|2005|   Hyundai|         Sonata|       Sedan|   automatic|   fl|  Average|201112.0|silver| 50|        2000|Jan 13 2015|         2015|           Jan|\n",
      "|2002|     Dodge|        Durango|         SUV|   automatic|   nj|      Bad|220355.0|   red| 50|         700|Feb 18 2015|         2015|           Feb|\n",
      "|2001|  Chrysler|        Sebring| Convertible|   automatic|   md|  Average|194983.0| white| 50|         400|Feb 10 2015|         2015|           Feb|\n",
      "+----+----------+---------------+------------+------------+-----+---------+--------+------+---+------------+-----------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------------+------------------+\n",
      "|           avg_mmr|     avg_sellprice|\n",
      "+------------------+------------------+\n",
      "|13836.999773466347|13690.403670268623|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CREATE A TEMPORARY VIEW TO QUERY\n",
    "df.createOrReplaceTempView(\"usedCars\")\n",
    "\n",
    "# LOOK FOR OUTLIERS\n",
    "spark.sql('select * from usedCars where sellingPrice = 1').show() # two records where sellingPrice = 1: these should be removed\n",
    "\n",
    "spark.sql('select * from usedCars where odometer = 999999.0').show()\n",
    "spark.sql('select count(*) as records from usedCars where odometer = 999999.0').show() # sixty records where odometer = 999,999.0; these should be removed\n",
    "\n",
    "spark.sql('select * from usedCars where mmr < 100 order by mmr').show() # mmr values are significantly lower than sale date, but looks reasonable\n",
    "\n",
    "spark.sql('select avg(mmr) as avg_mmr, avg(sellingprice) as avg_sellprice from usedCars').show() # mmr is about $140 higher than sale price\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d64ad4-e3f1-4ce6-999d-82b5da10ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outliers(df):\n",
    "    '''\n",
    "    FUNCTION TAKES IN 1 PARAMETER\n",
    "    \n",
    "    PARAM 1 --> Dataframe to adjust\n",
    "    \n",
    "    Will return a new dataframe without the outliers\n",
    "    '''\n",
    "    \n",
    "    # FILTER OUT SELLINGPRICE = 1 AND ODOMETER = 999999.0\n",
    "    df = df.where(F.col(\"sellingprice\") != 1)\n",
    "    df = df.where(F.col(\"odometer\") != 999999.0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = filter_outliers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f12d9d-5b3c-4537-beee-abadffe01edf",
   "metadata": {},
   "source": [
    "## Scale Continous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1dfed6b-fdfc-4dad-8126-c64c407c0070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Dataframe:\n",
      "+----+-----+-------------------+-----+------------+-----+---------+--------+-----+-----+------------+-----------+-------------+--------------+-----------+---------------+-------------------+\n",
      "|year| make|              model| body|transmission|state|condition|odometer|color|  mmr|sellingprice|   saledate|saledate_year|saledate_month|year_Scaled|odometer_Scaled|sellingprice_Scaled|\n",
      "+----+-----+-------------------+-----+------------+-----+---------+--------+-----+-----+------------+-----------+-------------+--------------+-----------+---------------+-------------------+\n",
      "|2015|  Kia|            Sorento|  SUV|   automatic|   ca|    Great| 16639.0|white|20500|       21500|Dec 16 2014|         2014|           Dec|        1.0|          0.017|              0.093|\n",
      "|2015|  Kia|            Sorento|  SUV|   automatic|   ca|    Great|  9393.0|white|20800|       21500|Dec 16 2014|         2014|           Dec|        1.0|           0.01|              0.093|\n",
      "|2014|  BMW|           3 Series|Sedan|   automatic|   ca|    Great|  1331.0| gray|31900|       30000|Jan 15 2015|         2015|           Jan|       0.96|          0.001|               0.13|\n",
      "|2015|Volvo|                S60|Sedan|   automatic|   ca|    Great| 14282.0|white|27500|       27750|Jan 29 2015|         2015|           Jan|        1.0|          0.015|               0.12|\n",
      "|2014|  BMW|6 Series Gran Coupe|Sedan|   automatic|   ca|    Great|  2641.0| gray|66000|       67000|Dec 18 2014|         2014|           Dec|       0.96|          0.003|              0.291|\n",
      "+----+-----+-------------------+-----+------------+-----+---------+--------+-----+-----+------------+-----------+-------------+--------------+-----------+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def scale_cont_var(df):\n",
    "    # UDF for converting column type from vector to double type\n",
    "    unlist = udf(lambda x: round(float(list(x)[0]),3), DoubleType())\n",
    "\n",
    "    # Iterating over columns to be scaled\n",
    "    for i in [\"year\", \"odometer\", \"sellingprice\"]:\n",
    "        # VectorAssembler Transformation - Converting column to vector type\n",
    "        assembler = VectorAssembler(inputCols=[i],outputCol=i+\"_Vect\")\n",
    "\n",
    "        # MinMaxScaler Transformation\n",
    "        scaler = MinMaxScaler(inputCol=i+\"_Vect\", outputCol=i+\"_Scaled\")\n",
    "\n",
    "        # Pipeline of VectorAssembler and MinMaxScaler\n",
    "        pipeline = Pipeline(stages=[assembler, scaler])\n",
    "\n",
    "        # Fitting pipeline on dataframe\n",
    "        df = pipeline.fit(df).transform(df).withColumn(i+\"_Scaled\", unlist(i+\"_Scaled\")).drop(i+\"_Vect\")\n",
    "\n",
    "    print(\"Scaled Dataframe:\")\n",
    "    df.show(5)\n",
    "    \n",
    "scale_cont_var(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f7607-4005-41e3-aa23-ccff6a8e8a77",
   "metadata": {},
   "source": [
    "## Look for Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d334e09d-829e-4d8e-9cb9-cc349c4fd4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|         make|         avg_price|\n",
      "+-------------+------------------+\n",
      "|  Rolls-Royce|         153456.25|\n",
      "|      Ferrari|128852.94117647059|\n",
      "|  Lamborghini|          111500.0|\n",
      "|      Bentley| 72713.33333333333|\n",
      "|        Tesla| 67054.34782608696|\n",
      "| Aston Martin|           55500.0|\n",
      "|       Fisker| 46461.11111111111|\n",
      "|     Maserati| 43729.81651376147|\n",
      "|        Lotus|           40800.0|\n",
      "|      Porsche|38932.109766637856|\n",
      "|   Land Rover| 33225.28744326778|\n",
      "|          Ram|25257.458209693374|\n",
      "|Mercedes-Benz|21320.646172522138|\n",
      "|          BMW|21293.283902661944|\n",
      "|     Infiniti| 20562.79630290486|\n",
      "|        Lexus|20286.116929285166|\n",
      "|         Audi|20010.167638483967|\n",
      "|       Jaguar|19429.853619729514|\n",
      "|      Lincoln| 17547.19143321153|\n",
      "|          GMC| 16769.46783118151|\n",
      "+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+--------------------+------------------+\n",
      "|         make|               model|         avg_price|\n",
      "+-------------+--------------------+------------------+\n",
      "|      Ferrari|          458 Italia|          183000.0|\n",
      "|Mercedes-Benz|          SLS AMG GT|          156500.0|\n",
      "|          BMW|                  i8|154222.22222222222|\n",
      "|  Rolls-Royce|               Ghost|         153456.25|\n",
      "|      Ferrari|          California|131846.15384615384|\n",
      "|Mercedes-Benz|             SLS AMG|116016.66666666667|\n",
      "|  Lamborghini|            Gallardo|          111500.0|\n",
      "|      Bentley|Continental GTC S...|          111000.0|\n",
      "|      Ferrari|                F430|          106250.0|\n",
      "|      Bentley|Continental Flyin...|          105750.0|\n",
      "|         Audi|                RS 7|          102225.0|\n",
      "|      Bentley|Continental Super...|          101000.0|\n",
      "| Aston Martin|              Rapide|           98750.0|\n",
      "|         Audi|                  R8|        91117.1875|\n",
      "|          BMW|       M6 Gran Coupe| 90913.63636363637|\n",
      "|      Bentley|     Continental GTC|           89560.0|\n",
      "|      Ferrari|                 360|           81000.0|\n",
      "|Mercedes-Benz|             G-Class| 80543.85964912281|\n",
      "|      Bentley|Continental GT Speed|           79750.0|\n",
      "|     Maserati|GranTurismo Conve...| 75090.90909090909|\n",
      "+-------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sql_query_clusters(df):\n",
    "    # CREATE A TEMPORARY VIEW TO QUERY\n",
    "    df.createOrReplaceTempView(\"usedCars\")\n",
    "\n",
    "    spark.sql('select make, avg(sellingprice) as avg_price from usedCars group by make order by avg_price desc').show()\n",
    "\n",
    "    spark.sql('select make, model, avg(sellingprice) as avg_price from usedCars group by make, model order by avg_price desc').show() # make-model looks promising, maybe quartiles?\n",
    "    \n",
    "sql_query_clusters(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2217d8-8f2b-4d8c-b10d-9b80b5072cbc",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "PUT IN WORK FOR \n",
    "JERRY, PRAFULLA, SARAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d76757-9bc6-420a-878b-03c8b74df29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94415865-da98-4aec-91bd-1ff686acbe33",
   "metadata": {},
   "source": [
    "# Modeling and Predictions\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f30026dc-c8e4-4d8a-81df-ec9016d7881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(df):\n",
    "    '''\n",
    "    FUNCTION TAKES IN 2 PARAMETERS:\n",
    "    1. Data Frame --> data frame that you are working with that you want to process\n",
    "    2. Column Names --> these are the categorical columns that will be used for processing/transformed\n",
    "    \n",
    "    Methods applied:\n",
    "    1. Indexing --> Get index of string columns\n",
    "    2. One hot encoding --> categorical values to numerical values\n",
    "    3. Assembler --> vectorizing encoded values\n",
    "    4. Pipeline --> create a pipeline do bring all these processes together\n",
    "    \n",
    "    Returns a transformed model as a dataframe\n",
    "    '''\n",
    "    \n",
    "    # 1. INDEXER\n",
    "    \n",
    "    cc = names = ['year', 'make', 'model', 'body', 'transmission', 'state', 'condition',\n",
    "       'odometer', 'color', 'mmr', 'saledate', 'saledate_year',\n",
    "       'saledate_month', 'year_Scaled', 'odometer_Scaled',\n",
    "       'sellingprice_Scaled']\n",
    "    indexers = [StringIndexer(inputCol = column, outputCol = f'{column}_indexed') for column in cc]\n",
    "    \n",
    "    # 2. One Hot Encoding\n",
    "    \n",
    "    encoders = [OneHotEncoder(dropLast = False, inputCol = idx.getOutputCol(), outputCol = f'{idx.getOutputCol()}_encoded') for idx in indexers]\n",
    "    \n",
    "    # 3. Assembler --> Vectorize encoded values\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols = [encoded_val.getOutputCol() for encoded_val in encoders], outputCol = 'features')\n",
    "    \n",
    "    # 4. Pipeline\n",
    "    \n",
    "    pipeline = Pipeline(stages = indexers + encoders + [assembler])\n",
    "    \n",
    "    \n",
    "    # Return our transformed moder\n",
    "    model = pipeline.fit(df)\n",
    "    \n",
    "    transformed_df = model.transform(df)\n",
    "    \n",
    "    return transformed_df\n",
    "\n",
    "\n",
    "trans_df = data_processing(df)\n",
    "# trans_df.printSchema()\n",
    "trans_df = trans_df.select(['features', 'sellingprice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c68b470-b3c1-4af2-840b-c287a493793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, split):\n",
    "    '''\n",
    "    FUNCTION TAKES IN 2 PARAMETERS:\n",
    "    1. DATAFRAME --> Dataframe that will be split (the one from above that was transformed)\n",
    "    2. SPLITS --> list with split1 and split 2 (ex: 0.7, 0.3)\n",
    "    \n",
    "    RETURN:\n",
    "    - train_df : split[0]\n",
    "    - test_df : split[1]\n",
    "    '''\n",
    "    \n",
    "    splits = df.randomSplit(split)\n",
    "    \n",
    "    return splits[0], splits[1]\n",
    "\n",
    "\n",
    "split_list = [0.7, 0.3]\n",
    "df_train, df_test = train_test_split(trans_df, split_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c87ef2d-cf31-4a10-aed5-191070904642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 820.81\n",
      "r2: 0.99\n"
     ]
    }
   ],
   "source": [
    "def create_linear_reg_model(train, test):\n",
    "    '''\n",
    "    FUNCTION TAKES IN 2 PARAMETERS AND RETURNS A LINEAR MODEL\n",
    "    \n",
    "    PARAM 1 --> TRAIN dataset\n",
    "    PARAM 2 --> TEST dataset\n",
    "    \n",
    "    \n",
    "    OVERVIEW:\n",
    "    Function will create a linear regression model and print RMSE and r2.\n",
    "    It will aslo return the linear regression model for predictions\n",
    "    '''\n",
    "    \n",
    "    lr_model = LinearRegression(\n",
    "        featuresCol = 'features',\n",
    "        labelCol = 'sellingprice',\n",
    "        maxIter = 10,\n",
    "        regParam = 0.3,\n",
    "        elasticNetParam = 0.8\n",
    "    )\n",
    "    \n",
    "    linear_model = lr_model.fit(train)\n",
    "    \n",
    "    trainSummary = linear_model.summary\n",
    "    print(\n",
    "        f'RMSE: {round(trainSummary.rootMeanSquaredError, 2)}'\n",
    "    )\n",
    "    print(\n",
    "        f'r2: {round(trainSummary.r2, 2)}'\n",
    "    )\n",
    "    \n",
    "    return linear_model\n",
    "    \n",
    "linear_model = create_linear_reg_model(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9e699f3-f817-4259-be15-df36fc365eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 820.81\n",
      "r2: 0.99\n"
     ]
    }
   ],
   "source": [
    "def create_grad_boost_tree_model(train, test):\n",
    "    '''\n",
    "    FUNCTION TAKES IN 2 PARAMETERS AND RETURNS A GRADIENT BOOSTED TREE REGRESSION MODEL\n",
    "    \n",
    "    PARAM 1 --> TRAIN dataset\n",
    "    PARAM 2 --> TEST dataset\n",
    "    \n",
    "    \n",
    "    OVERVIEW:\n",
    "    Function will create a linear regression model and print RMSE and r2.\n",
    "    It will aslo return the linear regression model for predictions\n",
    "    '''\n",
    "    \n",
    "    gbt_model = GBTRegressor(\n",
    "        fearturesCol = 'features',\n",
    "        labelCol = 'sellingprice',\n",
    "        maxIter = 10\n",
    "    )\n",
    "    \n",
    "    \n",
    "    gradientBoost_model = gbt_model.fit(train)\n",
    "    \n",
    "    trainSummary = gradientBoost_model.summary\n",
    "    print(\n",
    "        f'RMSE: {round(trainSummary.rootMeanSquaredError, 2)}'\n",
    "    )\n",
    "    print(\n",
    "        f'r2: {round(trainSummary.r2, 2)}'\n",
    "    )\n",
    "    return gradientBoost_model\n",
    "\n",
    "\n",
    "gbtr_model = create_linear_reg_model(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bfd93820-afc2-423f-95d7-41d0f916f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, test, model_name):\n",
    "    '''\n",
    "    FUNCTION TAKES IN 2 PARAMETERS\n",
    "    \n",
    "    PARAM 1 -- Model created\n",
    "    PARAM 2 -- test dataset\n",
    "    \n",
    "    OVERVIEW:\n",
    "    Function will create predictions and will evaluate the predictions for R2 and RMSE\n",
    "    \n",
    "    Will return a predictions dataframe\n",
    "    '''\n",
    "    \n",
    "    predictions = model.transform(test)\n",
    "    \n",
    "    model_eval = RegressionEvaluator(\n",
    "        predictionCol = 'prediction',\n",
    "        labelCol = 'sellingprice',\n",
    "        metricName = 'r2')\n",
    "    modelEval = model.evaluate(test)\n",
    "    \n",
    "    \n",
    "    print(f'Stats for {model_name}:')\n",
    "    print(f'R2 on test data: {model_eval.evaluate(predictions)}')\n",
    "    print(f'RMSE on test data: {modelEval.rootMeanSquaredError}')\n",
    "\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "271b06c6-c4a4-412b-a22c-3297875616f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for Linear Model:\n",
      "R2 on test data: 0.9681359645408623\n",
      "RMSE on test data: 1720.2704335014698\n"
     ]
    }
   ],
   "source": [
    "linear_model_predictions = make_predictions(linear_model, df_test, 'Linear Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a405db4b-c0e4-4327-a93f-593ac32c909d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|        prediction|sellingprice|\n",
      "+------------------+------------+\n",
      "|13022.313186622936|       13600|\n",
      "|15654.466222819825|       15900|\n",
      "|16264.766153311339|       18000|\n",
      "|14828.590856072722|       14000|\n",
      "|16309.797190502122|       16200|\n",
      "|10807.857743528712|       12400|\n",
      "|13279.314760497566|       11700|\n",
      "|11650.370012603827|        9800|\n",
      "|7315.5448677606455|       10000|\n",
      "| 11677.59749694638|       12700|\n",
      "|10233.827069652802|       11700|\n",
      "| 15506.25340481593|       16300|\n",
      "|14477.345019574652|       15200|\n",
      "|14432.875798095381|       15100|\n",
      "|17194.175712102828|       18100|\n",
      "|13811.492151328634|       13800|\n",
      "|15456.514246224688|       15600|\n",
      "| 14405.69604717595|       14300|\n",
      "|16345.451954548962|       15700|\n",
      "|17544.037236401164|       18700|\n",
      "+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at the predictions\n",
    "linear_model_predictions.select('prediction', 'sellingprice').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da8d82d6-778e-4c06-9b35-245c87faa953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for Gradient Boosted Tree Regressor:\n",
      "R2 on test data: 0.9681359645408623\n",
      "RMSE on test data: 1720.2704335014698\n"
     ]
    }
   ],
   "source": [
    "gbtr_model_predictions = make_predictions(gbtr_model, df_test, 'Gradient Boosted Tree Regressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "24dd2be5-f8be-470d-98e4-6d8f2bdf9458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|        prediction|sellingprice|\n",
      "+------------------+------------+\n",
      "|13022.313186622936|       13600|\n",
      "|15654.466222819825|       15900|\n",
      "|16264.766153311339|       18000|\n",
      "|14828.590856072722|       14000|\n",
      "|16309.797190502122|       16200|\n",
      "|10807.857743528712|       12400|\n",
      "|13279.314760497566|       11700|\n",
      "|11650.370012603827|        9800|\n",
      "|7315.5448677606455|       10000|\n",
      "| 11677.59749694638|       12700|\n",
      "|10233.827069652802|       11700|\n",
      "| 15506.25340481593|       16300|\n",
      "|14477.345019574652|       15200|\n",
      "|14432.875798095381|       15100|\n",
      "|17194.175712102828|       18100|\n",
      "|13811.492151328634|       13800|\n",
      "|15456.514246224688|       15600|\n",
      "| 14405.69604717595|       14300|\n",
      "|16345.451954548962|       15700|\n",
      "|17544.037236401164|       18700|\n",
      "+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbtr_model_predictions.select('prediction', 'sellingprice').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
